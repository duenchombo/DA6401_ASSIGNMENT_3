{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KyE0L0-n7X50"
      },
      "source": [
        "# **Importing required libraries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bQYDsJecC7Ku"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import csv\n",
        "import pandas as pd\n",
        "import random\n",
        "from tensorflow.keras import Input, Model\n",
        "from tensorflow.keras.layers import LSTM, SimpleRNN, GRU, Embedding, Dense, TimeDistributed, Concatenate, AdditiveAttention "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install wandb\n",
        "import wandb\n",
        "\n",
        "try:\n",
        "    from kaggle_secrets import UserSecretsClient\n",
        "    user_secrets = UserSecretsClient()\n",
        "    api_key = user_secrets.get_secret(\"wandb_api\")\n",
        "    wandb.login(key=api_key)\n",
        "    anony = None\n",
        "except:\n",
        "    anony = \"must\"\n",
        "    print('If you want to use your W&B account, go to Add-ons -> Secrets and provide your W&B access token. Use the Label name as wandb_api. \\nGet your W&B access token from here: https://wandb.ai/authorize')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WnEZvPl28qoS"
      },
      "source": [
        "# **Train,Test and Dev Data uploaded in kaggle**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "twh5WZtEECS7"
      },
      "outputs": [],
      "source": [
        "tsv_file = open(\"/kaggle/input/hi-translit/hi.translit.sampled.train.tsv\")\n",
        "read_tsv = csv.reader(tsv_file, delimiter=\"\\t\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u8Id1WLmxt7s"
      },
      "outputs": [],
      "source": [
        "val_tsv_file = open(\"/kaggle/input/hi-translit/hi.translit.sampled.dev.tsv\")\n",
        "val_read_tsv = csv.reader(val_tsv_file, delimiter=\"\\t\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kmfFvzeW866A"
      },
      "source": [
        "# **Processing training and validation data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4g5aurnxFkbW"
      },
      "outputs": [],
      "source": [
        "# Training data\n",
        "devnagri = []\n",
        "english = []\n",
        "\n",
        "for i in read_tsv:   \n",
        "    devnagri.append(i[0])\n",
        "    english.append(i[1])\n",
        "\n",
        "devnagri = np.array(devnagri)\n",
        "english = np.array(english)\n",
        "\n",
        "# Validation data\n",
        "val_devnagri = []\n",
        "val_english = []\n",
        "\n",
        "for i in val_read_tsv:\n",
        "    val_devnagri.append(i[0])\n",
        "    val_english.append(i[1])\n",
        "\n",
        "val_devnagri = np.array(val_devnagri)\n",
        "val_english = np.array(val_english)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ug9QmqY2sTFu"
      },
      "outputs": [],
      "source": [
        "for i in range(devnagri.shape[0]):\n",
        "    devnagri[i] = \"\\t\" + devnagri[i] + \"\\n\"\n",
        "    \n",
        "for i in range(val_devnagri.shape[0]):\n",
        "    val_devnagri[i] = \"\\t\" + val_devnagri[i] + \"\\n\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D030eDYkGAph"
      },
      "outputs": [],
      "source": [
        "# Getting input and target language characters\n",
        "\n",
        "# Training set\n",
        "english_characters = set()\n",
        "devnagri_characters = set()\n",
        "\n",
        "for word in english:\n",
        "    for char in word:\n",
        "        if char not in english_characters:\n",
        "            english_characters.add(char)\n",
        "\n",
        "for word in devnagri:\n",
        "    for char in word:\n",
        "        if char not in devnagri_characters:\n",
        "            devnagri_characters.add(char)\n",
        "\n",
        "# Validation set\n",
        "v_english_characters = set()\n",
        "v_devnagri_characters = set()\n",
        "\n",
        "for word in val_english:\n",
        "    for char in word:\n",
        "        if char not in v_english_characters:\n",
        "            v_english_characters.add(char)\n",
        "\n",
        "for word in val_devnagri:\n",
        "    for char in word:\n",
        "        if char not in v_devnagri_characters:\n",
        "            v_devnagri_characters.add(char)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ei1sBXOgHfA9"
      },
      "outputs": [],
      "source": [
        "english_characters = sorted(list(english_characters))\n",
        "devnagri_characters = sorted(list(devnagri_characters))\n",
        "\n",
        "num_encoder_tokens = len(english_characters)\n",
        "num_decoder_tokens = len(devnagri_characters)\n",
        "\n",
        "max_encoder_seq_length = max([len(txt) for txt in english])\n",
        "max_decoder_seq_length = max([len(txt) for txt in devnagri])\n",
        "\n",
        "# print(\"Number of samples:\", len(english))\n",
        "# print(\"Number of unique input tokens:\", num_encoder_tokens)\n",
        "# print(\"Number of unique output tokens:\", num_decoder_tokens)\n",
        "# print(\"Max sequence length for inputs:\", max_encoder_seq_length)\n",
        "# print(\"Max sequence length for outputs:\", max_decoder_seq_length)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E__RRLttBOj_"
      },
      "source": [
        "# **Preparing Encoder and Decoder Inputs**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U4O8I420Tv8r"
      },
      "outputs": [],
      "source": [
        "# Preparing train encoder and decoder inputs\n",
        "\n",
        "input_token_index = dict([(char, i) for i, char in enumerate(english_characters)])\n",
        "target_token_index = dict([(char, i) for i, char in enumerate(devnagri_characters)])\n",
        "\n",
        "reverse_input_char_index = dict((i, char) for char, i in input_token_index.items())\n",
        "reverse_target_char_index = dict((i, char) for char, i in target_token_index.items())\n",
        "\n",
        "encoder_input_data = np.zeros((len(english), max_encoder_seq_length), dtype=\"float32\")\n",
        "decoder_input_data = np.zeros((len(english), max_decoder_seq_length), dtype=\"float32\")\n",
        "decoder_target_data = np.zeros((len(english), max_decoder_seq_length, num_decoder_tokens), dtype=\"float32\")\n",
        "\n",
        "for i, (english, devnagri) in enumerate(zip(english, devnagri)):\n",
        "    for t, char in enumerate(english):\n",
        "        encoder_input_data[i, t] = input_token_index[char]\n",
        "    \n",
        "    for t, char in enumerate(devnagri):\n",
        "        decoder_input_data[i, t] = target_token_index[char]\n",
        "        if t > 0:\n",
        "            # decoder_target_data will be ahead by one timestep and will not include the start character.\n",
        "            decoder_target_data[i, t - 1, target_token_index[char]] = 1.0    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s0T_CS5AZidG"
      },
      "outputs": [],
      "source": [
        "# Preparing validation encoder and decoder inputs\n",
        "\n",
        "encoder_val_input_data = np.zeros((len(val_english), max_encoder_seq_length), dtype=\"float32\")\n",
        "decoder_val_input_data = np.zeros((len(val_english), max_decoder_seq_length), dtype=\"float32\")\n",
        "decoder_val_target_data = np.zeros((len(val_english), max_decoder_seq_length, num_decoder_tokens), dtype=\"float32\")\n",
        "\n",
        "for i, (e, d) in enumerate(zip(val_english, val_devnagri)):\n",
        "    for t, char in enumerate(e):\n",
        "        encoder_val_input_data[i, t] = input_token_index[char]\n",
        "  \n",
        "    for t, char in enumerate(d):\n",
        "        decoder_val_input_data[i, t] =  target_token_index[char]\n",
        "        if t > 0:\n",
        "            # decoder_target_data will be ahead by one timestep and will not include the start character.\n",
        "            decoder_val_target_data[i, t - 1, target_token_index[char]] = 1.0   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vz_BxeCmBGPJ"
      },
      "source": [
        "# **Defining Seq2Seq Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "itjkckjgCoLW"
      },
      "outputs": [],
      "source": [
        "def training(input_embedding_size, dp, cell_type, hidden_layer_size, num_encoder_layers, num_decoder_layers):\n",
        "    \n",
        "    # ENCODER\n",
        "\n",
        "    encoder_inputs = Input(shape=(max_encoder_seq_length,))\n",
        "    encoder_embedding = Embedding(num_encoder_tokens, input_embedding_size, trainable=True)(encoder_inputs)\n",
        "    \n",
        "    encoder_layers = []\n",
        "    encoder_states = []    \n",
        "    if cell_type == 'RNN':\n",
        "        encoder = SimpleRNN(hidden_layer_size, return_sequences=True, return_state=True, dropout = dp)\n",
        "        encoder_layers.append(encoder)\n",
        "        encoder_outputs, state_h = encoder(encoder_embedding)\n",
        "        encoder_states.append([state_h])\n",
        "        if num_encoder_layers > 1:\n",
        "            encoder = SimpleRNN(hidden_layer_size,return_sequences=True,return_state=True, dropout = dp) \n",
        "            encoder_layers.append(encoder)\n",
        "            encoder_outputs, state_h2 = encoder(encoder_outputs)\n",
        "            encoder_states.append([state_h2])\n",
        "        if num_encoder_layers > 2:\n",
        "            encoder = SimpleRNN(hidden_layer_size,return_sequences=True,return_state=True, dropout = dp) \n",
        "            encoder_layers.append(encoder)\n",
        "            encoder_outputs, state_h3 = encoder(encoder_outputs)\n",
        "            encoder_states.append([state_h3])\n",
        "        \n",
        "    elif cell_type == 'GRU':\n",
        "        encoder = GRU(hidden_layer_size, return_sequences=True, return_state=True, dropout = dp)\n",
        "        encoder_layers.append(encoder)\n",
        "        encoder_outputs, state_h = encoder(encoder_embedding)\n",
        "        encoder_states.append([state_h])\n",
        "        if num_encoder_layers > 1:\n",
        "            encoder = GRU(hidden_layer_size,return_sequences=True,return_state=True, dropout = dp) \n",
        "            encoder_layers.append(encoder)\n",
        "            encoder_outputs, state_h2 = encoder(encoder_outputs)\n",
        "            encoder_states.append([state_h2])\n",
        "        if num_encoder_layers > 2:\n",
        "            encoder = GRU(hidden_layer_size,return_sequences=True,return_state=True, dropout = dp) \n",
        "            encoder_layers.append(encoder)\n",
        "            encoder_outputs, state_h3 = encoder(encoder_outputs)\n",
        "            encoder_states.append([state_h3])\n",
        "       \n",
        "    else:\n",
        "        encoder = LSTM(hidden_layer_size, return_sequences=True, return_state=True, dropout = dp)\n",
        "        encoder_layers.append(encoder)\n",
        "        encoder_outputs, state_h, state_c = encoder(encoder_embedding)\n",
        "        encoder_states.append([state_h, state_c])\n",
        "        if num_encoder_layers > 1:\n",
        "            encoder = LSTM(hidden_layer_size,return_sequences=True,return_state=True, dropout = dp) \n",
        "            encoder_layers.append(encoder)\n",
        "            encoder_outputs, state_h2, state_c2 = encoder(encoder_outputs)\n",
        "            encoder_states.append([state_h2, state_c2])\n",
        "        if num_encoder_layers > 2:\n",
        "            encoder = LSTM(hidden_layer_size,return_sequences=True,return_state=True, dropout = dp) \n",
        "            encoder_layers.append(encoder)\n",
        "            encoder_outputs, state_h3, state_c3 = encoder(encoder_outputs)\n",
        "            encoder_states.append([state_h3, state_c3])\n",
        "\n",
        "    \n",
        "    # DECODER\n",
        "\n",
        "    decoder_inputs = Input(shape=(max_decoder_seq_length,))\n",
        "    decoder_embedding = Embedding(num_decoder_tokens, input_embedding_size, trainable=True)(decoder_inputs)\n",
        "\n",
        "    # We set up our decoder to return full output sequences, and to return internal states as well. \n",
        "    # We don't use the return states in the training model, but we will use them in inference.\n",
        "    \n",
        "    decoder_layers = []\n",
        "    if cell_type == 'RNN':\n",
        "        decoder_RNN = SimpleRNN(hidden_layer_size, return_sequences=True, return_state=True, dropout = dp)\n",
        "        decoder_layers.append(decoder_RNN)\n",
        "        decoder_outputs, _ = decoder_RNN(decoder_embedding, initial_state=encoder_states[0])\n",
        "        if num_decoder_layers > 1:\n",
        "            decoder_RNN = SimpleRNN(hidden_layer_size, return_sequences=True, return_state=True, dropout = dp)\n",
        "            decoder_layers.append(decoder_RNN)\n",
        "            decoder_outputs, _  = decoder_RNN(decoder_outputs, initial_state=encoder_states[1])\n",
        "        if num_decoder_layers > 2:\n",
        "            decoder_RNN = SimpleRNN(hidden_layer_size, return_sequences=True, return_state=True, dropout = dp)\n",
        "            decoder_layers.append(decoder_RNN)\n",
        "            decoder_outputs, _  = decoder_RNN(decoder_outputs, initial_state=encoder_states[2])\n",
        "        \n",
        "    elif cell_type == 'GRU':\n",
        "        decoder_GRU = GRU(hidden_layer_size, return_sequences=True, return_state=True, dropout = dp)\n",
        "        decoder_layers.append(decoder_GRU)\n",
        "        decoder_outputs, _ = decoder_GRU(decoder_embedding, initial_state=encoder_states[0])\n",
        "        if num_decoder_layers > 1:\n",
        "            decoder_GRU = GRU(hidden_layer_size, return_sequences=True, return_state=True, dropout = dp)\n",
        "            decoder_layers.append(decoder_GRU)\n",
        "            decoder_outputs, _  = decoder_GRU(decoder_outputs, initial_state=encoder_states[1])\n",
        "        if num_decoder_layers > 2:\n",
        "            decoder_GRU = GRU(hidden_layer_size, return_sequences=True, return_state=True, dropout = dp)\n",
        "            decoder_layers.append(decoder_GRU)\n",
        "            decoder_outputs, _  = decoder_GRU(decoder_outputs, initial_state=encoder_states[2])\n",
        "      \n",
        "    else:\n",
        "        decoder_lstm = LSTM(hidden_layer_size, return_sequences=True, return_state=True, dropout = dp)\n",
        "        decoder_layers.append(decoder_lstm)\n",
        "        decoder_outputs, _ , _ = decoder_lstm(decoder_embedding, initial_state=encoder_states[0])\n",
        "        if num_decoder_layers > 1:\n",
        "            decoder_lstm = LSTM(hidden_layer_size, return_sequences=True, return_state=True, dropout = dp)\n",
        "            decoder_layers.append(decoder_lstm)\n",
        "            decoder_outputs, _ , _  = decoder_lstm(decoder_outputs, initial_state=encoder_states[1])\n",
        "        if num_decoder_layers > 2:\n",
        "            decoder_lstm = LSTM(hidden_layer_size, return_sequences=True, return_state=True, dropout = dp)\n",
        "            decoder_layers.append(decoder_lstm)\n",
        "            decoder_outputs, _ , _  = decoder_lstm(decoder_outputs, initial_state=encoder_states[2])\n",
        "       \n",
        "    decoder_dense = TimeDistributed(Dense(num_decoder_tokens, activation=\"softmax\"))\n",
        "    decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "    # MODEL\n",
        "    model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "    return model, encoder_layers, decoder_layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hwCPBckEupTX"
      },
      "source": [
        "# **Inference model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cvLRxv-cCoLa"
      },
      "outputs": [],
      "source": [
        "def inferencing(model,num_encoder_layers,num_decoder_layers,encoder_layers,decoder_layers,cell_type, hidden_layer_size):\n",
        "    \n",
        "    # ENCODER MODEL RECONSTRUCTION \n",
        "    encoder_inputs = model.input[0]  # input_1\n",
        "    encoder_states = []\n",
        "    enc_emb = model.layers[2]     # embedding 1\n",
        "    encoder_outputs = enc_emb(encoder_inputs)\n",
        "\n",
        "    if cell_type == 'RNN' or cell_type ==\"GRU\":\n",
        "        for i in range(num_encoder_layers):\n",
        "            encoder_outputs, state_h_enc = encoder_layers[i](encoder_outputs)\n",
        "            encoder_states += [state_h_enc] \n",
        "    else:\n",
        "        for i in range(num_encoder_layers):\n",
        "            encoder_outputs, state_h_enc, state_c_enc = encoder_layers[i](encoder_outputs)\n",
        "            encoder_states += [state_h_enc, state_c_enc]   \n",
        "\n",
        "    encoder_model = Model(encoder_inputs, encoder_states + [encoder_outputs])\n",
        "\n",
        "\n",
        "    # DECODER MODEL RECONSTRUCTION\n",
        "    input_names = [[\"input_100\",\"input_101\"],[\"input_102\",\"input_103\"],[\"input_104\",\"input_105\"],\"input_106\"]\n",
        "\n",
        "    decoder_inputs = model.input[1]       # input_2\n",
        "    decoder_embedding = model.layers[3]   # embedding 2\n",
        "    decoder_outputs = decoder_embedding(decoder_inputs)\n",
        "    decoder_states = []\n",
        "    decoder_states_inputs = []\n",
        "    \n",
        "    if cell_type == 'RNN' or cell_type ==\"GRU\":\n",
        "        for i in range(num_decoder_layers):\n",
        "            decoder_states_inputs += [Input(shape=(hidden_layer_size,), name=input_names[i][0])]\n",
        "        for i in range(num_decoder_layers):\n",
        "            decoder_outputs, state_h_dec = decoder_layers[i](decoder_outputs, initial_state=decoder_states_inputs[i])\n",
        "            decoder_states += [state_h_dec]\n",
        "    else:\n",
        "        for i in range(num_decoder_layers):\n",
        "            decoder_states_inputs += [Input(shape=(hidden_layer_size,), name=input_names[i][0]), Input(shape=(hidden_layer_size,), name=input_names[i][1])]\n",
        "        j = 0\n",
        "        for i in range(num_decoder_layers):\n",
        "            decoder_outputs, state_h_dec, state_c_dec = decoder_layers[i](decoder_outputs, initial_state=decoder_states_inputs[i+j:i+j+2])\n",
        "            decoder_states += [state_h_dec , state_c_dec]\n",
        "            j += 1\n",
        "\n",
        "    decoder_dense = model.layers[4+2*num_encoder_layers]\n",
        "    decoder_outputs = decoder_dense(decoder_outputs)\n",
        "    decoder_model = Model([decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states)\n",
        "\n",
        "    return encoder_model, decoder_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iKU9UeA7q75x"
      },
      "outputs": [],
      "source": [
        "def decode_sequence(input_seq,encoder_model,decoder_model):\n",
        "    # Encode the input as state vectors.\n",
        "    states_value = encoder_model.predict(input_seq)\n",
        "    states_value = states_value[:-1]\n",
        "    target_seq = np.zeros((1, 1)) \n",
        "    target_seq[0, 0] = target_token_index[\"\\t\"]\n",
        "    stop_condition = False\n",
        "    decoded_sentence = \"\"\n",
        "    while not stop_condition:\n",
        "        dec_ip = [target_seq]+states_value\n",
        "        output_tokens = decoder_model.predict(dec_ip)\n",
        "        sampled_token_index = np.argmax(output_tokens[0][0, -1, :])\n",
        "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
        "        decoded_sentence += sampled_char\n",
        "        if sampled_char == \"\\n\" or len(decoded_sentence) > max_decoder_seq_length:\n",
        "            stop_condition = True\n",
        "\n",
        "        target_seq = np.zeros((1, 1))\n",
        "        target_seq[0, 0] = sampled_token_index\n",
        "        states_value = output_tokens[1:]\n",
        "        \n",
        "    return decoded_sentence"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9rf15d9ABWI0"
      },
      "source": [
        "# **Fitting the model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f3tft1XVCoLY",
        "outputId": "fb414abe-fb07-49ad-ccc2-4ff6e033c3e7"
      },
      "outputs": [],
      "source": [
        "batch_size = 128        \n",
        "epochs = 10             \n",
        "input_embedding_size = 512\n",
        "hidden_layer_size = 256\n",
        "num_layers = 3\n",
        "num_encoder_layers = num_layers\n",
        "num_decoder_layers = num_layers\n",
        "dropout = 0.2\n",
        "cell_type = 'LSTM'\n",
        "\n",
        "# TRAIN\n",
        "model, encoder_layers, decoder_layers = training(input_embedding_size, dropout, cell_type, hidden_layer_size, num_encoder_layers, num_decoder_layers)\n",
        "\n",
        "# COMPILE\n",
        "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "# FIT\n",
        "model.fit(\n",
        "    [encoder_input_data, decoder_input_data],\n",
        "    decoder_target_data,\n",
        "    batch_size=batch_size,\n",
        "    epochs=epochs,\n",
        "    shuffle = True,\n",
        "    validation_data= ([encoder_val_input_data, decoder_val_input_data], decoder_val_target_data)\n",
        ")\n",
        "\n",
        "encoder_model, decoder_model = inferencing(model, num_encoder_layers, num_decoder_layers, encoder_layers, decoder_layers, cell_type, hidden_layer_size)\n",
        "correct = 0\n",
        "n = val_devnagri.shape[0]\n",
        "for i in range(n):\n",
        "    input = encoder_val_input_data[i:i+1]\n",
        "    output = decode_sequence(input,encoder_model, decoder_model)\n",
        "    if output.strip() == val_devnagri[i].strip():\n",
        "        correct += 1\n",
        "print(\"Validation accuracy : \", correct*100/n)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "ques1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
