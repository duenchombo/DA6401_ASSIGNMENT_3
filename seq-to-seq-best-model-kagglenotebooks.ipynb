{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KyE0L0-n7X50"
   },
   "source": [
    "# **Importing required libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T02:29:34.546964Z",
     "iopub.status.busy": "2025-05-20T02:29:34.546132Z",
     "iopub.status.idle": "2025-05-20T02:29:34.550781Z",
     "shell.execute_reply": "2025-05-20T02:29:34.550070Z",
     "shell.execute_reply.started": "2025-05-20T02:29:34.546933Z"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1747574390060,
     "user": {
      "displayName": "Duen michael",
      "userId": "08465798039295179789"
     },
     "user_tz": -330
    },
    "id": "bQYDsJecC7Ku",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import pandas as pd\n",
    "import random\n",
    "from tensorflow.keras import Input, Model\n",
    "from tensorflow.keras.layers import LSTM, SimpleRNN, GRU, Embedding, Dense, TimeDistributed, Concatenate, AdditiveAttention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T02:29:34.568542Z",
     "iopub.status.busy": "2025-05-20T02:29:34.568372Z",
     "iopub.status.idle": "2025-05-20T02:29:34.580605Z",
     "shell.execute_reply": "2025-05-20T02:29:34.579944Z",
     "shell.execute_reply.started": "2025-05-20T02:29:34.568512Z"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1747574401518,
     "user": {
      "displayName": "Duen michael",
      "userId": "08465798039295179789"
     },
     "user_tz": -330
    },
    "id": "jQEy8vUo2-BT",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import cv2\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WnEZvPl28qoS"
   },
   "source": [
    "#**Train,Test and Dev Data uploaded in kaggle**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T02:29:34.621044Z",
     "iopub.status.busy": "2025-05-20T02:29:34.620806Z",
     "iopub.status.idle": "2025-05-20T02:29:34.641294Z",
     "shell.execute_reply": "2025-05-20T02:29:34.640816Z",
     "shell.execute_reply.started": "2025-05-20T02:29:34.621024Z"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1747574427888,
     "user": {
      "displayName": "Duen michael",
      "userId": "08465798039295179789"
     },
     "user_tz": -330
    },
    "id": "twh5WZtEECS7",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "tsv_file = open(\"/kaggle/input/sequence-sequence/hi.translit.sampled.train.tsv\")\n",
    "read_tsv = csv.reader(tsv_file, delimiter=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T02:29:34.642096Z",
     "iopub.status.busy": "2025-05-20T02:29:34.641862Z",
     "iopub.status.idle": "2025-05-20T02:29:34.646020Z",
     "shell.execute_reply": "2025-05-20T02:29:34.645428Z",
     "shell.execute_reply.started": "2025-05-20T02:29:34.642081Z"
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1747574427900,
     "user": {
      "displayName": "Duen michael",
      "userId": "08465798039295179789"
     },
     "user_tz": -330
    },
    "id": "u8Id1WLmxt7s",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "val_tsv_file = open(\"/kaggle/input/sequence-sequence/hi.translit.sampled.dev.tsv\")\n",
    "val_read_tsv = csv.reader(val_tsv_file, delimiter=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T02:29:34.647674Z",
     "iopub.status.busy": "2025-05-20T02:29:34.647470Z",
     "iopub.status.idle": "2025-05-20T02:29:34.658580Z",
     "shell.execute_reply": "2025-05-20T02:29:34.657922Z",
     "shell.execute_reply.started": "2025-05-20T02:29:34.647661Z"
    },
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1747574427902,
     "user": {
      "displayName": "Duen michael",
      "userId": "08465798039295179789"
     },
     "user_tz": -330
    },
    "id": "s15tGAPM8v1S",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "test_tsv_file = open(\"/kaggle/input/sequence-sequence/hi.translit.sampled.test.tsv\")\n",
    "test_read_tsv = csv.reader(test_tsv_file, delimiter=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kmfFvzeW866A"
   },
   "source": [
    "# **Processing training, validation and test data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T02:29:34.679003Z",
     "iopub.status.busy": "2025-05-20T02:29:34.678809Z",
     "iopub.status.idle": "2025-05-20T02:29:34.756605Z",
     "shell.execute_reply": "2025-05-20T02:29:34.755991Z",
     "shell.execute_reply.started": "2025-05-20T02:29:34.678981Z"
    },
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1747574430633,
     "user": {
      "displayName": "Duen michael",
      "userId": "08465798039295179789"
     },
     "user_tz": -330
    },
    "id": "4g5aurnxFkbW",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Training data\n",
    "devnagri = []\n",
    "english = []\n",
    "\n",
    "for i in read_tsv:\n",
    "    devnagri.append(i[0])\n",
    "    english.append(i[1])\n",
    "\n",
    "devnagri = np.array(devnagri)\n",
    "english = np.array(english)\n",
    "\n",
    "# Validation data\n",
    "val_devnagri = []\n",
    "val_english = []\n",
    "\n",
    "for i in val_read_tsv:\n",
    "    val_devnagri.append(i[0])\n",
    "    val_english.append(i[1])\n",
    "\n",
    "val_devnagri = np.array(val_devnagri)\n",
    "val_english = np.array(val_english)\n",
    "\n",
    "# Test data\n",
    "test_devnagri = []\n",
    "test_english = []\n",
    "\n",
    "for i in test_read_tsv:\n",
    "    test_devnagri.append(i[0])\n",
    "    test_english.append(i[1])\n",
    "\n",
    "test_devnagri = np.array(test_devnagri)\n",
    "test_english = np.array(test_english)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T02:29:34.757411Z",
     "iopub.status.busy": "2025-05-20T02:29:34.757221Z",
     "iopub.status.idle": "2025-05-20T02:29:34.805318Z",
     "shell.execute_reply": "2025-05-20T02:29:34.804793Z",
     "shell.execute_reply.started": "2025-05-20T02:29:34.757397Z"
    },
    "executionInfo": {
     "elapsed": 48,
     "status": "ok",
     "timestamp": 1747574430680,
     "user": {
      "displayName": "Duen michael",
      "userId": "08465798039295179789"
     },
     "user_tz": -330
    },
    "id": "Ug9QmqY2sTFu",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "for i in range(devnagri.shape[0]):\n",
    "    devnagri[i] = \"\\t\" + devnagri[i] + \"\\n\"\n",
    "\n",
    "for i in range(val_devnagri.shape[0]):\n",
    "    val_devnagri[i] = \"\\t\" + val_devnagri[i] + \"\\n\"\n",
    "\n",
    "for i in range(test_devnagri.shape[0]):\n",
    "    test_devnagri[i] = \"\\t\" + test_devnagri[i] + \"\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T02:29:34.807052Z",
     "iopub.status.busy": "2025-05-20T02:29:34.806858Z",
     "iopub.status.idle": "2025-05-20T02:29:34.916185Z",
     "shell.execute_reply": "2025-05-20T02:29:34.915739Z",
     "shell.execute_reply.started": "2025-05-20T02:29:34.807037Z"
    },
    "executionInfo": {
     "elapsed": 113,
     "status": "ok",
     "timestamp": 1747574430795,
     "user": {
      "displayName": "Duen michael",
      "userId": "08465798039295179789"
     },
     "user_tz": -330
    },
    "id": "D030eDYkGAph",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Getting input and target language characters\n",
    "\n",
    "# Training set\n",
    "english_characters = set()\n",
    "devnagri_characters = set()\n",
    "\n",
    "for word in english:\n",
    "    for char in word:\n",
    "        if char not in english_characters:\n",
    "            english_characters.add(char)\n",
    "\n",
    "for word in devnagri:\n",
    "    for char in word:\n",
    "        if char not in devnagri_characters:\n",
    "            devnagri_characters.add(char)\n",
    "\n",
    "# Validation set\n",
    "v_english_characters = set()\n",
    "v_devnagri_characters = set()\n",
    "\n",
    "for word in val_english:\n",
    "    for char in word:\n",
    "        if char not in v_english_characters:\n",
    "            v_english_characters.add(char)\n",
    "\n",
    "for word in val_devnagri:\n",
    "    for char in word:\n",
    "        if char not in v_devnagri_characters:\n",
    "            v_devnagri_characters.add(char)\n",
    "\n",
    "# Test set\n",
    "t_english_characters = set()\n",
    "t_devnagri_characters = set()\n",
    "\n",
    "for word in test_english:\n",
    "    for char in word:\n",
    "        if char not in t_english_characters:\n",
    "            t_english_characters.add(char)\n",
    "\n",
    "for word in test_devnagri:\n",
    "    for char in word:\n",
    "        if char not in t_devnagri_characters:\n",
    "            t_devnagri_characters.add(char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T02:29:34.916910Z",
     "iopub.status.busy": "2025-05-20T02:29:34.916752Z",
     "iopub.status.idle": "2025-05-20T02:29:34.946539Z",
     "shell.execute_reply": "2025-05-20T02:29:34.945964Z",
     "shell.execute_reply.started": "2025-05-20T02:29:34.916898Z"
    },
    "executionInfo": {
     "elapsed": 36,
     "status": "ok",
     "timestamp": 1747574430837,
     "user": {
      "displayName": "Duen michael",
      "userId": "08465798039295179789"
     },
     "user_tz": -330
    },
    "id": "Ei1sBXOgHfA9",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "english_characters = sorted(list(english_characters))\n",
    "devnagri_characters = sorted(list(devnagri_characters))\n",
    "\n",
    "num_encoder_tokens = len(english_characters)\n",
    "num_decoder_tokens = len(devnagri_characters)\n",
    "\n",
    "max_encoder_seq_length = max([len(txt) for txt in english])\n",
    "max_decoder_seq_length = max([len(txt) for txt in devnagri])\n",
    "\n",
    "# print(\"Number of samples:\", len(english))\n",
    "# print(\"Number of unique input tokens:\", num_encoder_tokens)\n",
    "# print(\"Number of unique output tokens:\", num_decoder_tokens)\n",
    "# print(\"Max sequence length for inputs:\", max_encoder_seq_length)\n",
    "# print(\"Max sequence length for outputs:\", max_decoder_seq_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E__RRLttBOj_"
   },
   "source": [
    "# **Preparing Encoder and Decoder Inputs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T02:29:34.947422Z",
     "iopub.status.busy": "2025-05-20T02:29:34.947208Z",
     "iopub.status.idle": "2025-05-20T02:29:35.472604Z",
     "shell.execute_reply": "2025-05-20T02:29:35.471814Z",
     "shell.execute_reply.started": "2025-05-20T02:29:34.947399Z"
    },
    "executionInfo": {
     "elapsed": 513,
     "status": "ok",
     "timestamp": 1747574431362,
     "user": {
      "displayName": "Duen michael",
      "userId": "08465798039295179789"
     },
     "user_tz": -330
    },
    "id": "U4O8I420Tv8r",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Preparing train encoder and decoder inputs\n",
    "\n",
    "input_token_index = dict([(char, i) for i, char in enumerate(english_characters)])\n",
    "target_token_index = dict([(char, i) for i, char in enumerate(devnagri_characters)])\n",
    "\n",
    "reverse_input_char_index = dict((i, char) for char, i in input_token_index.items())\n",
    "reverse_target_char_index = dict((i, char) for char, i in target_token_index.items())\n",
    "\n",
    "encoder_input_data = np.zeros((len(english), max_encoder_seq_length), dtype=\"float32\")\n",
    "decoder_input_data = np.zeros((len(english), max_decoder_seq_length), dtype=\"float32\")\n",
    "decoder_target_data = np.zeros((len(english), max_decoder_seq_length, num_decoder_tokens), dtype=\"float32\")\n",
    "\n",
    "for i, (english, devnagri) in enumerate(zip(english, devnagri)):\n",
    "    for t, char in enumerate(english):\n",
    "        encoder_input_data[i, t] = input_token_index[char]\n",
    "\n",
    "    for t, char in enumerate(devnagri):\n",
    "        decoder_input_data[i, t] = target_token_index[char]\n",
    "        if t > 0:\n",
    "            # decoder_target_data will be ahead by one timestep and will not include the start character.\n",
    "            decoder_target_data[i, t - 1, target_token_index[char]] = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T02:29:35.473844Z",
     "iopub.status.busy": "2025-05-20T02:29:35.473452Z",
     "iopub.status.idle": "2025-05-20T02:29:35.531210Z",
     "shell.execute_reply": "2025-05-20T02:29:35.530537Z",
     "shell.execute_reply.started": "2025-05-20T02:29:35.473818Z"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1747574431366,
     "user": {
      "displayName": "Duen michael",
      "userId": "08465798039295179789"
     },
     "user_tz": -330
    },
    "id": "s0T_CS5AZidG",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Preparing validation encoder and decoder inputs\n",
    "\n",
    "encoder_val_input_data = np.zeros((len(val_english), max_encoder_seq_length), dtype=\"float32\")\n",
    "decoder_val_input_data = np.zeros((len(val_english), max_decoder_seq_length), dtype=\"float32\")\n",
    "decoder_val_target_data = np.zeros((len(val_english), max_decoder_seq_length, num_decoder_tokens), dtype=\"float32\")\n",
    "\n",
    "for i, (e, d) in enumerate(zip(val_english, val_devnagri)):\n",
    "    for t, char in enumerate(e):\n",
    "        encoder_val_input_data[i, t] = input_token_index[char]\n",
    "\n",
    "    for t, char in enumerate(d):\n",
    "        decoder_val_input_data[i, t] =  target_token_index[char]\n",
    "        if t > 0:\n",
    "            # decoder_target_data will be ahead by one timestep and will not include the start character.\n",
    "            decoder_val_target_data[i, t - 1, target_token_index[char]] = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T02:29:35.532205Z",
     "iopub.status.busy": "2025-05-20T02:29:35.531942Z",
     "iopub.status.idle": "2025-05-20T02:29:35.589400Z",
     "shell.execute_reply": "2025-05-20T02:29:35.588927Z",
     "shell.execute_reply.started": "2025-05-20T02:29:35.532187Z"
    },
    "executionInfo": {
     "elapsed": 95,
     "status": "ok",
     "timestamp": 1747574431464,
     "user": {
      "displayName": "Duen michael",
      "userId": "08465798039295179789"
     },
     "user_tz": -330
    },
    "id": "wssPWN9qBUwe",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Preparing test encoder and decoder inputs\n",
    "\n",
    "encoder_test_input_data = np.zeros((len(test_english), max_encoder_seq_length), dtype=\"float32\")\n",
    "decoder_test_input_data = np.zeros((len(test_english), max_decoder_seq_length), dtype=\"float32\")\n",
    "decoder_test_target_data = np.zeros((len(test_english), max_decoder_seq_length, num_decoder_tokens), dtype=\"float32\")\n",
    "\n",
    "for i, (e, d) in enumerate(zip(test_english, test_devnagri)):\n",
    "    for t, char in enumerate(e):\n",
    "        encoder_test_input_data[i, t] = input_token_index[char]\n",
    "\n",
    "    for t, char in enumerate(d):\n",
    "        decoder_test_input_data[i, t] =  target_token_index[char]\n",
    "        if t > 0:\n",
    "            # decoder_target_data will be ahead by one timestep and will not include the start character.\n",
    "            decoder_test_target_data[i, t - 1, target_token_index[char]] = 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vz_BxeCmBGPJ"
   },
   "source": [
    "# **Defining Seq2Seq Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T02:29:35.590160Z",
     "iopub.status.busy": "2025-05-20T02:29:35.589994Z",
     "iopub.status.idle": "2025-05-20T02:29:35.604616Z",
     "shell.execute_reply": "2025-05-20T02:29:35.604036Z",
     "shell.execute_reply.started": "2025-05-20T02:29:35.590147Z"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1747574431482,
     "user": {
      "displayName": "Duen michael",
      "userId": "08465798039295179789"
     },
     "user_tz": -330
    },
    "id": "itjkckjgCoLW",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def training(input_embedding_size, dp, cell_type, hidden_layer_size, num_encoder_layers, num_decoder_layers):\n",
    "\n",
    "    # ENCODER\n",
    "\n",
    "    encoder_inputs = Input(shape=(max_encoder_seq_length,))\n",
    "    encoder_embedding = Embedding(num_encoder_tokens, input_embedding_size, trainable=True)(encoder_inputs)\n",
    "\n",
    "    encoder_layers = []\n",
    "    encoder_states = []\n",
    "    if cell_type == 'RNN':\n",
    "        encoder = SimpleRNN(hidden_layer_size, return_sequences=True, return_state=True, dropout = dp)\n",
    "        encoder_layers.append(encoder)\n",
    "        encoder_outputs, state_h = encoder(encoder_embedding)\n",
    "        encoder_states.append([state_h])\n",
    "        if num_encoder_layers > 1:\n",
    "            encoder = SimpleRNN(hidden_layer_size,return_sequences=True,return_state=True, dropout = dp)\n",
    "            encoder_layers.append(encoder)\n",
    "            encoder_outputs, state_h2 = encoder(encoder_outputs)\n",
    "            encoder_states.append([state_h2])\n",
    "        if num_encoder_layers > 2:\n",
    "            encoder = SimpleRNN(hidden_layer_size,return_sequences=True,return_state=True, dropout = dp)\n",
    "            encoder_layers.append(encoder)\n",
    "            encoder_outputs, state_h3 = encoder(encoder_outputs)\n",
    "            encoder_states.append([state_h3])\n",
    "\n",
    "    elif cell_type == 'GRU':\n",
    "        encoder = GRU(hidden_layer_size, return_sequences=True, return_state=True, dropout = dp)\n",
    "        encoder_layers.append(encoder)\n",
    "        encoder_outputs, state_h = encoder(encoder_embedding)\n",
    "        encoder_states.append([state_h])\n",
    "        if num_encoder_layers > 1:\n",
    "            encoder = GRU(hidden_layer_size,return_sequences=True,return_state=True, dropout = dp)\n",
    "            encoder_layers.append(encoder)\n",
    "            encoder_outputs, state_h2 = encoder(encoder_outputs)\n",
    "            encoder_states.append([state_h2])\n",
    "        if num_encoder_layers > 2:\n",
    "            encoder = GRU(hidden_layer_size,return_sequences=True,return_state=True, dropout = dp)\n",
    "            encoder_layers.append(encoder)\n",
    "            encoder_outputs, state_h3 = encoder(encoder_outputs)\n",
    "            encoder_states.append([state_h3])\n",
    "\n",
    "    else:\n",
    "        encoder = LSTM(hidden_layer_size, return_sequences=True, return_state=True, dropout = dp)\n",
    "        encoder_layers.append(encoder)\n",
    "        encoder_outputs, state_h, state_c = encoder(encoder_embedding)\n",
    "        encoder_states.append([state_h, state_c])\n",
    "        if num_encoder_layers > 1:\n",
    "            encoder = LSTM(hidden_layer_size,return_sequences=True,return_state=True, dropout = dp)\n",
    "            encoder_layers.append(encoder)\n",
    "            encoder_outputs, state_h2, state_c2 = encoder(encoder_outputs)\n",
    "            encoder_states.append([state_h2, state_c2])\n",
    "        if num_encoder_layers > 2:\n",
    "            encoder = LSTM(hidden_layer_size,return_sequences=True,return_state=True, dropout = dp)\n",
    "            encoder_layers.append(encoder)\n",
    "            encoder_outputs, state_h3, state_c3 = encoder(encoder_outputs)\n",
    "            encoder_states.append([state_h3, state_c3])\n",
    "\n",
    "\n",
    "    # DECODER\n",
    "\n",
    "    decoder_inputs = Input(shape=(max_decoder_seq_length,))\n",
    "    decoder_embedding = Embedding(num_decoder_tokens, input_embedding_size, trainable=True)(decoder_inputs)\n",
    "\n",
    "    # We set up our decoder to return full output sequences, and to return internal states as well.\n",
    "    # We don't use the return states in the training model, but we will use them in inference.\n",
    "\n",
    "    decoder_layers = []\n",
    "    if cell_type == 'RNN':\n",
    "        decoder_RNN = SimpleRNN(hidden_layer_size, return_sequences=True, return_state=True, dropout = dp)\n",
    "        decoder_layers.append(decoder_RNN)\n",
    "        decoder_outputs, _ = decoder_RNN(decoder_embedding, initial_state=encoder_states[0])\n",
    "        if num_decoder_layers > 1:\n",
    "            decoder_RNN = SimpleRNN(hidden_layer_size, return_sequences=True, return_state=True, dropout = dp)\n",
    "            decoder_layers.append(decoder_RNN)\n",
    "            decoder_outputs, _  = decoder_RNN(decoder_outputs, initial_state=encoder_states[1])\n",
    "        if num_decoder_layers > 2:\n",
    "            decoder_RNN = SimpleRNN(hidden_layer_size, return_sequences=True, return_state=True, dropout = dp)\n",
    "            decoder_layers.append(decoder_RNN)\n",
    "            decoder_outputs, _  = decoder_RNN(decoder_outputs, initial_state=encoder_states[2])\n",
    "\n",
    "    elif cell_type == 'GRU':\n",
    "        decoder_GRU = GRU(hidden_layer_size, return_sequences=True, return_state=True, dropout = dp)\n",
    "        decoder_layers.append(decoder_GRU)\n",
    "        decoder_outputs, _ = decoder_GRU(decoder_embedding, initial_state=encoder_states[0])\n",
    "        if num_decoder_layers > 1:\n",
    "            decoder_GRU = GRU(hidden_layer_size, return_sequences=True, return_state=True, dropout = dp)\n",
    "            decoder_layers.append(decoder_GRU)\n",
    "            decoder_outputs, _  = decoder_GRU(decoder_outputs, initial_state=encoder_states[1])\n",
    "        if num_decoder_layers > 2:\n",
    "            decoder_GRU = GRU(hidden_layer_size, return_sequences=True, return_state=True, dropout = dp)\n",
    "            decoder_layers.append(decoder_GRU)\n",
    "            decoder_outputs, _  = decoder_GRU(decoder_outputs, initial_state=encoder_states[2])\n",
    "\n",
    "    else:\n",
    "        decoder_lstm = LSTM(hidden_layer_size, return_sequences=True, return_state=True, dropout = dp)\n",
    "        decoder_layers.append(decoder_lstm)\n",
    "        decoder_outputs, _ , _ = decoder_lstm(decoder_embedding, initial_state=encoder_states[0])\n",
    "        if num_decoder_layers > 1:\n",
    "            decoder_lstm = LSTM(hidden_layer_size, return_sequences=True, return_state=True, dropout = dp)\n",
    "            decoder_layers.append(decoder_lstm)\n",
    "            decoder_outputs, _ , _  = decoder_lstm(decoder_outputs, initial_state=encoder_states[1])\n",
    "        if num_decoder_layers > 2:\n",
    "            decoder_lstm = LSTM(hidden_layer_size, return_sequences=True, return_state=True, dropout = dp)\n",
    "            decoder_layers.append(decoder_lstm)\n",
    "            decoder_outputs, _ , _  = decoder_lstm(decoder_outputs, initial_state=encoder_states[2])\n",
    "\n",
    "    decoder_dense = TimeDistributed(Dense(num_decoder_tokens, activation=\"softmax\"))\n",
    "    decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "    # MODEL\n",
    "    model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "    return model, encoder_layers, decoder_layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hwCPBckEupTX"
   },
   "source": [
    "# **Inference model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T02:29:35.605438Z",
     "iopub.status.busy": "2025-05-20T02:29:35.605249Z",
     "iopub.status.idle": "2025-05-20T02:29:35.621947Z",
     "shell.execute_reply": "2025-05-20T02:29:35.621213Z",
     "shell.execute_reply.started": "2025-05-20T02:29:35.605415Z"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1747574431483,
     "user": {
      "displayName": "Duen michael",
      "userId": "08465798039295179789"
     },
     "user_tz": -330
    },
    "id": "cvLRxv-cCoLa",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def inferencing(model,num_encoder_layers,num_decoder_layers,encoder_layers,decoder_layers,cell_type, hidden_layer_size):\n",
    "\n",
    "    # ENCODER MODEL RECONSTRUCTION\n",
    "    encoder_inputs = model.input[0]  # input_1\n",
    "    encoder_states = []\n",
    "    enc_emb = model.layers[2]     # embedding 1\n",
    "    encoder_outputs = enc_emb(encoder_inputs)\n",
    "\n",
    "    if cell_type == 'RNN' or cell_type ==\"GRU\":\n",
    "        for i in range(num_encoder_layers):\n",
    "            encoder_outputs, state_h_enc = encoder_layers[i](encoder_outputs)\n",
    "            encoder_states += [state_h_enc]\n",
    "    else:\n",
    "        for i in range(num_encoder_layers):\n",
    "            encoder_outputs, state_h_enc, state_c_enc = encoder_layers[i](encoder_outputs)\n",
    "            encoder_states += [state_h_enc, state_c_enc]\n",
    "\n",
    "    encoder_model = Model(encoder_inputs, encoder_states + [encoder_outputs])\n",
    "\n",
    "\n",
    "    # DECODER MODEL RECONSTRUCTION\n",
    "    input_names = [[\"input_100\",\"input_101\"],[\"input_102\",\"input_103\"],[\"input_104\",\"input_105\"],\"input_106\"]\n",
    "\n",
    "    decoder_inputs = model.input[1]       # input_2\n",
    "    decoder_embedding = model.layers[3]   # embedding 2\n",
    "    decoder_outputs = decoder_embedding(decoder_inputs)\n",
    "    decoder_states = []\n",
    "    decoder_states_inputs = []\n",
    "\n",
    "    if cell_type == 'RNN' or cell_type ==\"GRU\":\n",
    "        for i in range(num_decoder_layers):\n",
    "            decoder_states_inputs += [Input(shape=(hidden_layer_size,), name=input_names[i][0])]\n",
    "        for i in range(num_decoder_layers):\n",
    "            decoder_outputs, state_h_dec = decoder_layers[i](decoder_outputs, initial_state=decoder_states_inputs[i])\n",
    "            decoder_states += [state_h_dec]\n",
    "    else:\n",
    "        for i in range(num_decoder_layers):\n",
    "            decoder_states_inputs += [Input(shape=(hidden_layer_size,), name=input_names[i][0]), Input(shape=(hidden_layer_size,), name=input_names[i][1])]\n",
    "        j = 0\n",
    "        for i in range(num_decoder_layers):\n",
    "            decoder_outputs, state_h_dec, state_c_dec = decoder_layers[i](decoder_outputs, initial_state=decoder_states_inputs[i+j:i+j+2])\n",
    "            decoder_states += [state_h_dec , state_c_dec]\n",
    "            j += 1\n",
    "\n",
    "    decoder_dense = model.layers[4+2*num_encoder_layers]\n",
    "    decoder_outputs = decoder_dense(decoder_outputs)\n",
    "    decoder_model = Model([decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states)\n",
    "\n",
    "    return encoder_model, decoder_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T02:29:35.624134Z",
     "iopub.status.busy": "2025-05-20T02:29:35.623926Z",
     "iopub.status.idle": "2025-05-20T02:29:35.637571Z",
     "shell.execute_reply": "2025-05-20T02:29:35.637014Z",
     "shell.execute_reply.started": "2025-05-20T02:29:35.624120Z"
    },
    "executionInfo": {
     "elapsed": 23,
     "status": "ok",
     "timestamp": 1747574431503,
     "user": {
      "displayName": "Duen michael",
      "userId": "08465798039295179789"
     },
     "user_tz": -330
    },
    "id": "iKU9UeA7q75x",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# def decode_sequence(input_seq,encoder_model,decoder_model):\n",
    "#     # Encode the input as state vectors.\n",
    "#     states_value = encoder_model.predict(input_seq,verbose=0)\n",
    "#     states_value = states_value[:-1]\n",
    "#     target_seq = np.zeros((1, 1))\n",
    "#     target_seq[0, 0] = target_token_index[\"\\t\"]\n",
    "#     stop_condition = False\n",
    "#     decoded_sentence = \"\"\n",
    "#     while not stop_condition:\n",
    "#         dec_ip = [target_seq]+states_value\n",
    "#         output_tokens = decoder_model.predict(dec_ip,verbose=0)\n",
    "#         sampled_token_index = np.argmax(output_tokens[0][0, -1, :])\n",
    "#         sampled_char = reverse_target_char_index[sampled_token_index]\n",
    "#         decoded_sentence += sampled_char\n",
    "#         if sampled_char == \"\\n\" or len(decoded_sentence) > max_decoder_seq_length:\n",
    "#             stop_condition = True\n",
    "\n",
    "#         target_seq = np.zeros((1, 1))\n",
    "#         target_seq[0, 0] = sampled_token_index\n",
    "#         states_value = output_tokens[1:]\n",
    "\n",
    "#     return decoded_sentence\n",
    "\n",
    "\n",
    "\n",
    "def decode_sequence_from_states(states_value, decoder_model):\n",
    "    target_seq = np.zeros((1, 1))\n",
    "    target_seq[0, 0] = target_token_index[\"\\t\"]\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = \"\"\n",
    "\n",
    "    while not stop_condition:\n",
    "        dec_ip = [target_seq] + states_value\n",
    "        output_tokens = decoder_model.predict(dec_ip, verbose=0)\n",
    "\n",
    "        sampled_token_index = np.argmax(output_tokens[0][0, -1, :])\n",
    "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
    "        decoded_sentence += sampled_char\n",
    "\n",
    "        if sampled_char == \"\\n\" or len(decoded_sentence) > max_decoder_seq_length:\n",
    "            stop_condition = True\n",
    "\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "        states_value = output_tokens[1:]\n",
    "\n",
    "    return decoded_sentence\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9rf15d9ABWI0"
   },
   "source": [
    "# **Fitting the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-05-20T02:29:35.638357Z",
     "iopub.status.busy": "2025-05-20T02:29:35.638183Z",
     "iopub.status.idle": "2025-05-20T02:31:49.077041Z",
     "shell.execute_reply": "2025-05-20T02:31:49.076416Z",
     "shell.execute_reply.started": "2025-05-20T02:29:35.638344Z"
    },
    "executionInfo": {
     "elapsed": 211002,
     "status": "ok",
     "timestamp": 1747574643598,
     "user": {
      "displayName": "Duen michael",
      "userId": "08465798039295179789"
     },
     "user_tz": -330
    },
    "id": "f3tft1XVCoLY",
    "outputId": "2fb042bb-fd2c-42af-c5e6-dfa0fb04f419",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1747708176.708759      35 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15513 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1747708190.027051     102 cuda_dnn.cc:529] Loaded cuDNN version 90300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 38ms/step - accuracy: 0.0760 - loss: 1.2051 - val_accuracy: 0.1081 - val_loss: 0.9305\n",
      "Epoch 2/10\n",
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 34ms/step - accuracy: 0.1378 - loss: 0.8748 - val_accuracy: 0.1945 - val_loss: 0.5840\n",
      "Epoch 3/10\n",
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 34ms/step - accuracy: 0.2268 - loss: 0.5180 - val_accuracy: 0.2560 - val_loss: 0.3502\n",
      "Epoch 4/10\n",
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 34ms/step - accuracy: 0.2852 - loss: 0.3113 - val_accuracy: 0.2825 - val_loss: 0.2614\n",
      "Epoch 5/10\n",
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 34ms/step - accuracy: 0.3108 - loss: 0.2205 - val_accuracy: 0.2936 - val_loss: 0.2219\n",
      "Epoch 6/10\n",
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 33ms/step - accuracy: 0.3259 - loss: 0.1755 - val_accuracy: 0.2986 - val_loss: 0.2064\n",
      "Epoch 7/10\n",
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 33ms/step - accuracy: 0.3341 - loss: 0.1473 - val_accuracy: 0.3005 - val_loss: 0.2015\n",
      "Epoch 8/10\n",
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 33ms/step - accuracy: 0.3410 - loss: 0.1266 - val_accuracy: 0.3033 - val_loss: 0.1940\n",
      "Epoch 9/10\n",
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 33ms/step - accuracy: 0.3463 - loss: 0.1125 - val_accuracy: 0.3029 - val_loss: 0.1971\n",
      "Epoch 10/10\n",
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 33ms/step - accuracy: 0.3499 - loss: 0.0979 - val_accuracy: 0.3030 - val_loss: 0.1994\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x79e82f342910>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 128\n",
    "epochs = 10\n",
    "input_embedding_size = 512\n",
    "hidden_layer_size = 256\n",
    "num_layers = 3\n",
    "num_encoder_layers = num_layers\n",
    "num_decoder_layers = num_layers\n",
    "dropout = 0.1\n",
    "cell_type = 'LSTM'\n",
    "\n",
    "# TRAIN\n",
    "model, encoder_layers, decoder_layers = training(input_embedding_size, dropout, cell_type, hidden_layer_size, num_encoder_layers, num_decoder_layers)\n",
    "\n",
    "# COMPILE\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# FIT\n",
    "model.fit(\n",
    "    [encoder_input_data, decoder_input_data],\n",
    "    decoder_target_data,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    shuffle = True,\n",
    "    validation_data= ([encoder_val_input_data, decoder_val_input_data], decoder_val_target_data)\n",
    ")\n",
    "\n",
    "# encoder_model, decoder_model = inferencing(model, num_encoder_layers, num_decoder_layers, encoder_layers, decoder_layers, cell_type, hidden_layer_size)\n",
    "# correct = 0\n",
    "# n = val_devnagri.shape[0]\n",
    "# for i in range(n):\n",
    "#     input = encoder_val_input_data[i:i+1]\n",
    "#     output = decode_sequence(input,encoder_model, decoder_model)\n",
    "#     if output.strip() == val_devnagri[i].strip():\n",
    "#         correct += 1\n",
    "# print(\"Validation accuracy : \", correct*100/n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cAEJeXHt3Gze"
   },
   "source": [
    "# **Predictions on test set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 228
    },
    "execution": {
     "iopub.execute_input": "2025-05-20T02:31:49.078041Z",
     "iopub.status.busy": "2025-05-20T02:31:49.077814Z",
     "iopub.status.idle": "2025-05-20T03:25:25.288057Z",
     "shell.execute_reply": "2025-05-20T03:25:25.287292Z",
     "shell.execute_reply.started": "2025-05-20T02:31:49.078014Z"
    },
    "executionInfo": {
     "elapsed": 225,
     "status": "error",
     "timestamp": 1747580326727,
     "user": {
      "displayName": "Duen michael",
      "userId": "08465798039295179789"
     },
     "user_tz": -330
    },
    "id": "QehJccbi4Atl",
    "outputId": "0069343d-25f4-433a-f623-d83d2d91dac6",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy :  31.363838294091515\n"
     ]
    }
   ],
   "source": [
    "# encoder_model, decoder_model = inferencing(model, num_encoder_layers, num_decoder_layers, encoder_layers, decoder_layers, cell_type, hidden_layer_size)\n",
    "# correct = 0\n",
    "# predictions = []\n",
    "# n = test_devnagri.shape[0]\n",
    "# for i in range(n):\n",
    "#     input = encoder_test_input_data[i:i+1]\n",
    "#     output = decode_sequence(input,encoder_model, decoder_model)\n",
    "#     if output.strip() == test_devnagri[i].strip():\n",
    "#         correct += 1\n",
    "#     predictions.append(output.strip())\n",
    "# print(\"Test accuracy : \", correct*100/n)\n",
    "\n",
    "encoder_model, decoder_model = inferencing(model, num_encoder_layers, num_decoder_layers, encoder_layers, decoder_layers, cell_type, hidden_layer_size)\n",
    "all_states = encoder_model.predict(encoder_test_input_data, verbose=0)\n",
    "all_states = all_states[:-1]  # drop encoder_outputs\n",
    "\n",
    "# 2. Loop through test data\n",
    "correct = 0\n",
    "predictions = []\n",
    "n = test_devnagri.shape[0]\n",
    "\n",
    "for i in range(n):\n",
    "    # Extract i-th encoder state from each state tensor\n",
    "    states_value = [state[i:i+1] for state in all_states]\n",
    "\n",
    "    # Decode\n",
    "    output = decode_sequence_from_states(states_value, decoder_model)\n",
    "\n",
    "    # Compare\n",
    "    if output.strip() == test_devnagri[i].strip():\n",
    "        correct += 1\n",
    "    predictions.append(output.strip())\n",
    "\n",
    "print(\"Test accuracy : \", correct * 100 / n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T03:30:57.720498Z",
     "iopub.status.busy": "2025-05-20T03:30:57.720198Z",
     "iopub.status.idle": "2025-05-20T03:30:57.741779Z",
     "shell.execute_reply": "2025-05-20T03:30:57.741084Z",
     "shell.execute_reply.started": "2025-05-20T03:30:57.720477Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "with open('/kaggle/working/predictions_vanilla.csv', 'w', newline='', encoding='utf-8', errors='ignore') as file:\n",
    "    header = ['Input', 'Prediction', 'Ground Truth']\n",
    "    writer = csv.DictWriter(file, fieldnames=header)\n",
    "    writer.writeheader()\n",
    "    for i in range(n):\n",
    "        writer.writerow({\n",
    "            'Input': test_english[i],\n",
    "            'Prediction': predictions[i],\n",
    "            'Ground Truth': test_devnagri[i]\n",
    "        })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bwjkNt1lIJCR"
   },
   "source": [
    "# **Displaying grid**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T03:34:48.424992Z",
     "iopub.status.busy": "2025-05-20T03:34:48.424694Z",
     "iopub.status.idle": "2025-05-20T03:34:48.431154Z",
     "shell.execute_reply": "2025-05-20T03:34:48.430330Z",
     "shell.execute_reply.started": "2025-05-20T03:34:48.424970Z"
    },
    "id": "nAeZItLtIx_m",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def display_images( images, columns=5, width=22, height=10):\n",
    "    height = max(height, int(len(images)/columns) * 5)\n",
    "    plt.figure(figsize=(width, height))\n",
    "    for i, image in enumerate(images):\n",
    "        plt.subplot(int(len(images) / columns + 1), columns, i + 1)\n",
    "        plt.tick_params(axis='both', which='both', bottom=False, top=False, labelbottom=False, right=False, left=False, labelleft=False)\n",
    "        plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T03:44:58.464983Z",
     "iopub.status.busy": "2025-05-20T03:44:58.464024Z",
     "iopub.status.idle": "2025-05-20T03:44:58.469747Z",
     "shell.execute_reply": "2025-05-20T03:44:58.468723Z",
     "shell.execute_reply.started": "2025-05-20T03:44:58.464951Z"
    },
    "id": "qvFm68R45CBz",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "arial_dir=r\"/kaggle/input/sequence-sequence/arial.ttf\"\n",
    "mangal_dir=r\"/kaggle/input/sequence-sequence/MANGAL.TTF\"\n",
    "\n",
    "\n",
    "\n",
    "img = []\n",
    "for i in range(10):\n",
    "    img.append(Image.new('RGBA', (150, 150), color = (10, 200, 210, 140)))\n",
    "    d = ImageDraw.Draw(img[i])\n",
    "    d.line(((65, 80), (75, 90), (85, 80)), fill=(0, 0, 0), width=2)\n",
    "    d.line(((75, 52), (75, 90)), fill=(0, 0, 0), width=2)\n",
    "    text1 = test_english[i*355]\n",
    "    text2 = \"\\n\" + predictions[i*355]\n",
    "    arial = ImageFont.truetype(arial_dir, 20)\n",
    "    mangal = ImageFont.truetype(mangal_dir, 20)\n",
    "    # arial = ImageFont.truetype('arial.ttf', 20)\n",
    "    # mangal = ImageFont.truetype('MANGAL.TTF', 20)\n",
    "    w1,h1 = arial.getsize(text1)\n",
    "    w2,h2 = mangal.getsize(text2)\n",
    "    d.text((75-w1/2, 35-h1/2), text1 , fill=(0,0,0), font = arial)\n",
    "    d.text((77-w2/2, 77-h2/2), text2, font = mangal,  fill=(0,0,0))\n",
    "\n",
    "display_images(img)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 7459741,
     "sourceId": 11870481,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
