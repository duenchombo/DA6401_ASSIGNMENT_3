{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KyE0L0-n7X50"
   },
   "source": [
    "# **Importing required libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T04:53:29.428456Z",
     "iopub.status.busy": "2025-05-20T04:53:29.427747Z",
     "iopub.status.idle": "2025-05-20T04:53:42.849140Z",
     "shell.execute_reply": "2025-05-20T04:53:42.848511Z",
     "shell.execute_reply.started": "2025-05-20T04:53:29.428427Z"
    },
    "id": "bQYDsJecC7Ku",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-20 04:53:31.138976: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1747716811.325058      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1747716811.381495      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import pandas as pd\n",
    "import random\n",
    "from tensorflow.keras import Input, Model\n",
    "from tensorflow.keras.layers import LSTM, SimpleRNN, GRU, Embedding, Dense, TimeDistributed, Concatenate, AdditiveAttention "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T04:55:38.934787Z",
     "iopub.status.busy": "2025-05-20T04:55:38.934110Z",
     "iopub.status.idle": "2025-05-20T04:55:48.276526Z",
     "shell.execute_reply": "2025-05-20T04:55:48.275871Z",
     "shell.execute_reply.started": "2025-05-20T04:55:38.934741Z"
    },
    "id": "ebd9RN8Az2lo",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wandb in /usr/local/lib/python3.11/dist-packages (0.19.9)\n",
      "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.11/dist-packages (from wandb) (8.1.8)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (3.1.44)\n",
      "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb) (4.3.8)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (3.20.3)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (7.0.0)\n",
      "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.11.4)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from wandb) (6.0.2)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.32.3)\n",
      "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.25.1)\n",
      "Requirement already satisfied: setproctitle in /usr/local/lib/python3.11/dist-packages (from wandb) (1.3.5)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from wandb) (75.2.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.4 in /usr/local/lib/python3.11/dist-packages (from wandb) (4.13.2)\n",
      "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.17.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (0.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2025.4.26)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mduenchombo1\u001b[0m (\u001b[33mduenchombo1-indian-institute-of-technology-madras\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "!pip install wandb\n",
    "import wandb\n",
    "\n",
    "try:\n",
    "    from kaggle_secrets import UserSecretsClient\n",
    "    user_secrets = UserSecretsClient()\n",
    "    api_key = user_secrets.get_secret(\"wandb_api\")\n",
    "    wandb.login(key=api_key)\n",
    "    anony = None\n",
    "except:\n",
    "    anony = \"must\"\n",
    "    print('If you want to use your W&B account, go to Add-ons -> Secrets and provide your W&B access token. Use the Label name as wandb_api. \\nGet your W&B access token from here: https://wandb.ai/authorize')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T04:55:56.460884Z",
     "iopub.status.busy": "2025-05-20T04:55:56.460301Z",
     "iopub.status.idle": "2025-05-20T04:55:56.465184Z",
     "shell.execute_reply": "2025-05-20T04:55:56.464583Z",
     "shell.execute_reply.started": "2025-05-20T04:55:56.460850Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.font_manager import FontProperties\n",
    "from IPython.display import HTML as html_print\n",
    "import time\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WnEZvPl28qoS"
   },
   "source": [
    "# **Train,Test and Dev Data uploaded in kaggle**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T04:57:46.450637Z",
     "iopub.status.busy": "2025-05-20T04:57:46.450058Z",
     "iopub.status.idle": "2025-05-20T04:57:46.457306Z",
     "shell.execute_reply": "2025-05-20T04:57:46.456644Z",
     "shell.execute_reply.started": "2025-05-20T04:57:46.450613Z"
    },
    "id": "twh5WZtEECS7",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "tsv_file = open(\"/kaggle/input/devgri/hi.translit.sampled.train.tsv\")\n",
    "read_tsv = csv.reader(tsv_file, delimiter=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T04:57:48.762004Z",
     "iopub.status.busy": "2025-05-20T04:57:48.761335Z",
     "iopub.status.idle": "2025-05-20T04:57:48.765653Z",
     "shell.execute_reply": "2025-05-20T04:57:48.765037Z",
     "shell.execute_reply.started": "2025-05-20T04:57:48.761978Z"
    },
    "id": "u8Id1WLmxt7s",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "val_tsv_file = open(\"/kaggle/input/devgri/hi.translit.sampled.train.tsv\")\n",
    "val_read_tsv = csv.reader(val_tsv_file, delimiter=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T04:57:51.573720Z",
     "iopub.status.busy": "2025-05-20T04:57:51.573455Z",
     "iopub.status.idle": "2025-05-20T04:57:51.578646Z",
     "shell.execute_reply": "2025-05-20T04:57:51.577941Z",
     "shell.execute_reply.started": "2025-05-20T04:57:51.573699Z"
    },
    "id": "s15tGAPM8v1S",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "test_tsv_file = open(\"/kaggle/input/devgri/hi.translit.sampled.test.tsv\")\n",
    "test_read_tsv = csv.reader(test_tsv_file, delimiter=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kmfFvzeW866A"
   },
   "source": [
    "# **Processing training, validation and test data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T04:57:57.542217Z",
     "iopub.status.busy": "2025-05-20T04:57:57.541961Z",
     "iopub.status.idle": "2025-05-20T04:57:57.673526Z",
     "shell.execute_reply": "2025-05-20T04:57:57.672994Z",
     "shell.execute_reply.started": "2025-05-20T04:57:57.542198Z"
    },
    "id": "4g5aurnxFkbW",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Training data\n",
    "devnagri = []\n",
    "english = []\n",
    "\n",
    "for i in read_tsv:   \n",
    "    devnagri.append(i[0])\n",
    "    english.append(i[1])\n",
    "\n",
    "devnagri = np.array(devnagri)\n",
    "english = np.array(english)\n",
    "\n",
    "# Validation data\n",
    "val_devnagri = []\n",
    "val_english = []\n",
    "\n",
    "for i in val_read_tsv:\n",
    "    val_devnagri.append(i[0])\n",
    "    val_english.append(i[1])\n",
    "\n",
    "val_devnagri = np.array(val_devnagri)\n",
    "val_english = np.array(val_english)\n",
    "\n",
    "# Test data\n",
    "test_devnagri = []\n",
    "test_english = []\n",
    "\n",
    "for i in test_read_tsv:\n",
    "    test_devnagri.append(i[0])\n",
    "    test_english.append(i[1])\n",
    "\n",
    "test_devnagri = np.array(test_devnagri)\n",
    "test_english = np.array(test_english)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T04:58:02.204836Z",
     "iopub.status.busy": "2025-05-20T04:58:02.204575Z",
     "iopub.status.idle": "2025-05-20T04:58:02.274015Z",
     "shell.execute_reply": "2025-05-20T04:58:02.273292Z",
     "shell.execute_reply.started": "2025-05-20T04:58:02.204817Z"
    },
    "id": "Ug9QmqY2sTFu",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "for i in range(devnagri.shape[0]):\n",
    "    devnagri[i] = \"\\t\" + devnagri[i] + \"\\n\"\n",
    "    \n",
    "for i in range(val_devnagri.shape[0]):\n",
    "    val_devnagri[i] = \"\\t\" + val_devnagri[i] + \"\\n\"\n",
    "\n",
    "for i in range(test_devnagri.shape[0]):\n",
    "    test_devnagri[i] = \"\\t\" + test_devnagri[i] + \"\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T04:58:04.950239Z",
     "iopub.status.busy": "2025-05-20T04:58:04.949574Z",
     "iopub.status.idle": "2025-05-20T04:58:05.145185Z",
     "shell.execute_reply": "2025-05-20T04:58:05.144646Z",
     "shell.execute_reply.started": "2025-05-20T04:58:04.950214Z"
    },
    "id": "D030eDYkGAph",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Getting input and target language characters\n",
    "\n",
    "# Training set\n",
    "english_characters = set()\n",
    "devnagri_characters = set()\n",
    "\n",
    "for word in english:\n",
    "    for char in word:\n",
    "        if char not in english_characters:\n",
    "            english_characters.add(char)\n",
    "\n",
    "for word in devnagri:\n",
    "    for char in word:\n",
    "        if char not in devnagri_characters:\n",
    "            devnagri_characters.add(char)\n",
    "\n",
    "# Validation set\n",
    "v_english_characters = set()\n",
    "v_devnagri_characters = set()\n",
    "\n",
    "for word in val_english:\n",
    "    for char in word:\n",
    "        if char not in v_english_characters:\n",
    "            v_english_characters.add(char)\n",
    "\n",
    "for word in val_devnagri:\n",
    "    for char in word:\n",
    "        if char not in v_devnagri_characters:\n",
    "            v_devnagri_characters.add(char)\n",
    "\n",
    "# Test set\n",
    "t_english_characters = set()\n",
    "t_devnagri_characters = set()\n",
    "\n",
    "for word in test_english:\n",
    "    for char in word:\n",
    "        if char not in t_english_characters:\n",
    "            t_english_characters.add(char)\n",
    "\n",
    "for word in test_devnagri:\n",
    "    for char in word:\n",
    "        if char not in t_devnagri_characters:\n",
    "            t_devnagri_characters.add(char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T04:58:08.556874Z",
     "iopub.status.busy": "2025-05-20T04:58:08.556331Z",
     "iopub.status.idle": "2025-05-20T04:58:08.585726Z",
     "shell.execute_reply": "2025-05-20T04:58:08.585227Z",
     "shell.execute_reply.started": "2025-05-20T04:58:08.556851Z"
    },
    "id": "Ei1sBXOgHfA9",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "english_characters = sorted(list(english_characters))\n",
    "devnagri_characters = sorted(list(devnagri_characters))\n",
    "\n",
    "num_encoder_tokens = len(english_characters)\n",
    "num_decoder_tokens = len(devnagri_characters)\n",
    "\n",
    "max_encoder_seq_length = max([len(txt) for txt in english])\n",
    "max_decoder_seq_length = max([len(txt) for txt in devnagri])\n",
    "\n",
    "# print(\"Number of samples:\", len(english))\n",
    "# print(\"Number of unique input tokens:\", num_encoder_tokens)\n",
    "# print(\"Number of unique output tokens:\", num_decoder_tokens)\n",
    "# print(\"Max sequence length for inputs:\", max_encoder_seq_length)\n",
    "# print(\"Max sequence length for outputs:\", max_decoder_seq_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E__RRLttBOj_"
   },
   "source": [
    "# **Preparing Encoder and Decoder Inputs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T04:58:11.749101Z",
     "iopub.status.busy": "2025-05-20T04:58:11.748183Z",
     "iopub.status.idle": "2025-05-20T04:58:12.263389Z",
     "shell.execute_reply": "2025-05-20T04:58:12.262607Z",
     "shell.execute_reply.started": "2025-05-20T04:58:11.749062Z"
    },
    "id": "U4O8I420Tv8r",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Preparing train encoder and decoder inputs\n",
    "\n",
    "input_token_index = dict([(char, i) for i, char in enumerate(english_characters)])\n",
    "target_token_index = dict([(char, i) for i, char in enumerate(devnagri_characters)])\n",
    "\n",
    "reverse_input_char_index = dict((i, char) for char, i in input_token_index.items())\n",
    "reverse_target_char_index = dict((i, char) for char, i in target_token_index.items())\n",
    "\n",
    "encoder_input_data = np.zeros((len(english), max_encoder_seq_length), dtype=\"float32\")\n",
    "decoder_input_data = np.zeros((len(english), max_decoder_seq_length), dtype=\"float32\")\n",
    "decoder_target_data = np.zeros((len(english), max_decoder_seq_length, num_decoder_tokens), dtype=\"float32\")\n",
    "\n",
    "for i, (english, devnagri) in enumerate(zip(english, devnagri)):\n",
    "    for t, char in enumerate(english):\n",
    "        encoder_input_data[i, t] = input_token_index[char]\n",
    "    \n",
    "    for t, char in enumerate(devnagri):\n",
    "        decoder_input_data[i, t] = target_token_index[char]\n",
    "        if t > 0:\n",
    "            # decoder_target_data will be ahead by one timestep and will not include the start character.\n",
    "            decoder_target_data[i, t - 1, target_token_index[char]] = 1.0    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T04:58:15.197508Z",
     "iopub.status.busy": "2025-05-20T04:58:15.197248Z",
     "iopub.status.idle": "2025-05-20T04:58:15.686907Z",
     "shell.execute_reply": "2025-05-20T04:58:15.686368Z",
     "shell.execute_reply.started": "2025-05-20T04:58:15.197489Z"
    },
    "id": "s0T_CS5AZidG",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Preparing validation encoder and decoder inputs\n",
    "\n",
    "encoder_val_input_data = np.zeros((len(val_english), max_encoder_seq_length), dtype=\"float32\")\n",
    "decoder_val_input_data = np.zeros((len(val_english), max_decoder_seq_length), dtype=\"float32\")\n",
    "decoder_val_target_data = np.zeros((len(val_english), max_decoder_seq_length, num_decoder_tokens), dtype=\"float32\")\n",
    "\n",
    "for i, (e, d) in enumerate(zip(val_english, val_devnagri)):\n",
    "    for t, char in enumerate(e):\n",
    "        encoder_val_input_data[i, t] = input_token_index[char]\n",
    "  \n",
    "    for t, char in enumerate(d):\n",
    "        decoder_val_input_data[i, t] =  target_token_index[char]\n",
    "        if t > 0:\n",
    "            # decoder_target_data will be ahead by one timestep and will not include the start character.\n",
    "            decoder_val_target_data[i, t - 1, target_token_index[char]] = 1.0   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T04:58:18.717730Z",
     "iopub.status.busy": "2025-05-20T04:58:18.717470Z",
     "iopub.status.idle": "2025-05-20T04:58:18.773855Z",
     "shell.execute_reply": "2025-05-20T04:58:18.773352Z",
     "shell.execute_reply.started": "2025-05-20T04:58:18.717709Z"
    },
    "id": "wssPWN9qBUwe",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Preparing test encoder and decoder inputs\n",
    "\n",
    "encoder_test_input_data = np.zeros((len(test_english), max_encoder_seq_length), dtype=\"float32\")\n",
    "decoder_test_input_data = np.zeros((len(test_english), max_decoder_seq_length), dtype=\"float32\")\n",
    "decoder_test_target_data = np.zeros((len(test_english), max_decoder_seq_length, num_decoder_tokens), dtype=\"float32\")\n",
    "\n",
    "for i, (e, d) in enumerate(zip(test_english, test_devnagri)):\n",
    "    for t, char in enumerate(e):\n",
    "        encoder_test_input_data[i, t] = input_token_index[char]\n",
    "    \n",
    "    for t, char in enumerate(d):\n",
    "        decoder_test_input_data[i, t] =  target_token_index[char]\n",
    "        if t > 0:\n",
    "            # decoder_target_data will be ahead by one timestep and will not include the start character.\n",
    "            decoder_test_target_data[i, t - 1, target_token_index[char]] = 1.0   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vz_BxeCmBGPJ"
   },
   "source": [
    "# **Defining Seq2Seq Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T04:58:22.495852Z",
     "iopub.status.busy": "2025-05-20T04:58:22.495592Z",
     "iopub.status.idle": "2025-05-20T04:58:22.511825Z",
     "shell.execute_reply": "2025-05-20T04:58:22.511225Z",
     "shell.execute_reply.started": "2025-05-20T04:58:22.495834Z"
    },
    "id": "itjkckjgCoLW",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def training(input_embedding_size, dp, cell_type, hidden_layer_size, num_encoder_layers, num_decoder_layers):\n",
    "    \n",
    "    # ENCODER\n",
    "\n",
    "    encoder_inputs = Input(shape=(max_encoder_seq_length,))\n",
    "    encoder_embedding = Embedding(num_encoder_tokens, input_embedding_size, trainable=True)(encoder_inputs)\n",
    "    \n",
    "    encoder_layers = []\n",
    "    encoder_states = []    \n",
    "    if cell_type == 'RNN':\n",
    "        encoder = SimpleRNN(hidden_layer_size, return_sequences=True, return_state=True, dropout = dp)\n",
    "        encoder_layers.append(encoder)\n",
    "        encoder_outputs, state_h = encoder(encoder_embedding)\n",
    "        encoder_states.append([state_h])\n",
    "        if num_encoder_layers > 1:\n",
    "            encoder = SimpleRNN(hidden_layer_size,return_sequences=True,return_state=True, dropout = dp) \n",
    "            encoder_layers.append(encoder)\n",
    "            encoder_outputs, state_h2 = encoder(encoder_outputs)\n",
    "            encoder_states.append([state_h2])\n",
    "        if num_encoder_layers > 2:\n",
    "            encoder = SimpleRNN(hidden_layer_size,return_sequences=True,return_state=True, dropout = dp) \n",
    "            encoder_layers.append(encoder)\n",
    "            encoder_outputs, state_h3 = encoder(encoder_outputs)\n",
    "            encoder_states.append([state_h3])\n",
    "        \n",
    "    elif cell_type == 'GRU':\n",
    "        encoder = GRU(hidden_layer_size, return_sequences=True, return_state=True, dropout = dp)\n",
    "        encoder_layers.append(encoder)\n",
    "        encoder_outputs, state_h = encoder(encoder_embedding)\n",
    "        encoder_states.append([state_h])\n",
    "        if num_encoder_layers > 1:\n",
    "            encoder = GRU(hidden_layer_size,return_sequences=True,return_state=True, dropout = dp) \n",
    "            encoder_layers.append(encoder)\n",
    "            encoder_outputs, state_h2 = encoder(encoder_outputs)\n",
    "            encoder_states.append([state_h2])\n",
    "        if num_encoder_layers > 2:\n",
    "            encoder = GRU(hidden_layer_size,return_sequences=True,return_state=True, dropout = dp) \n",
    "            encoder_layers.append(encoder)\n",
    "            encoder_outputs, state_h3 = encoder(encoder_outputs)\n",
    "            encoder_states.append([state_h3])\n",
    "       \n",
    "    else:\n",
    "        encoder = LSTM(hidden_layer_size, return_sequences=True, return_state=True, dropout = dp)\n",
    "        encoder_layers.append(encoder)\n",
    "        encoder_outputs, state_h, state_c = encoder(encoder_embedding)\n",
    "        encoder_states.append([state_h, state_c])\n",
    "        if num_encoder_layers > 1:\n",
    "            encoder = LSTM(hidden_layer_size,return_sequences=True,return_state=True, dropout = dp) \n",
    "            encoder_layers.append(encoder)\n",
    "            encoder_outputs, state_h2, state_c2 = encoder(encoder_outputs)\n",
    "            encoder_states.append([state_h2, state_c2])\n",
    "        if num_encoder_layers > 2:\n",
    "            encoder = LSTM(hidden_layer_size,return_sequences=True,return_state=True, dropout = dp) \n",
    "            encoder_layers.append(encoder)\n",
    "            encoder_outputs, state_h3, state_c3 = encoder(encoder_outputs)\n",
    "            encoder_states.append([state_h3, state_c3])\n",
    "\n",
    "    \n",
    "    # DECODER\n",
    "\n",
    "    decoder_inputs = Input(shape=(max_decoder_seq_length,))\n",
    "    decoder_embedding = Embedding(num_decoder_tokens, input_embedding_size, trainable=True)(decoder_inputs)\n",
    "\n",
    "    # We set up our decoder to return full output sequences, and to return internal states as well. \n",
    "    # We don't use the return states in the training model, but we will use them in inference.\n",
    "    \n",
    "    decoder_layers = []\n",
    "    if cell_type == 'RNN':\n",
    "        decoder_RNN = SimpleRNN(hidden_layer_size, return_sequences=True, return_state=True, dropout = dp)\n",
    "        decoder_layers.append(decoder_RNN)\n",
    "        decoder_outputs, _ = decoder_RNN(decoder_embedding, initial_state=encoder_states[0])\n",
    "        if num_decoder_layers > 1:\n",
    "            decoder_RNN = SimpleRNN(hidden_layer_size, return_sequences=True, return_state=True, dropout = dp)\n",
    "            decoder_layers.append(decoder_RNN)\n",
    "            decoder_outputs, _  = decoder_RNN(decoder_outputs, initial_state=encoder_states[1])\n",
    "        if num_decoder_layers > 2:\n",
    "            decoder_RNN = SimpleRNN(hidden_layer_size, return_sequences=True, return_state=True, dropout = dp)\n",
    "            decoder_layers.append(decoder_RNN)\n",
    "            decoder_outputs, _  = decoder_RNN(decoder_outputs, initial_state=encoder_states[2])\n",
    "        \n",
    "    elif cell_type == 'GRU':\n",
    "        decoder_GRU = GRU(hidden_layer_size, return_sequences=True, return_state=True, dropout = dp)\n",
    "        decoder_layers.append(decoder_GRU)\n",
    "        decoder_outputs, _ = decoder_GRU(decoder_embedding, initial_state=encoder_states[0])\n",
    "        if num_decoder_layers > 1:\n",
    "            decoder_GRU = GRU(hidden_layer_size, return_sequences=True, return_state=True, dropout = dp)\n",
    "            decoder_layers.append(decoder_GRU)\n",
    "            decoder_outputs, _  = decoder_GRU(decoder_outputs, initial_state=encoder_states[1])\n",
    "        if num_decoder_layers > 2:\n",
    "            decoder_GRU = GRU(hidden_layer_size, return_sequences=True, return_state=True, dropout = dp)\n",
    "            decoder_layers.append(decoder_GRU)\n",
    "            decoder_outputs, _  = decoder_GRU(decoder_outputs, initial_state=encoder_states[2])\n",
    "      \n",
    "    else:\n",
    "        decoder_lstm = LSTM(hidden_layer_size, return_sequences=True, return_state=True, dropout = dp)\n",
    "        decoder_layers.append(decoder_lstm)\n",
    "        decoder_outputs, _ , _ = decoder_lstm(decoder_embedding, initial_state=encoder_states[0])\n",
    "        if num_decoder_layers > 1:\n",
    "            decoder_lstm = LSTM(hidden_layer_size, return_sequences=True, return_state=True, dropout = dp)\n",
    "            decoder_layers.append(decoder_lstm)\n",
    "            decoder_outputs, _ , _  = decoder_lstm(decoder_outputs, initial_state=encoder_states[1])\n",
    "        if num_decoder_layers > 2:\n",
    "            decoder_lstm = LSTM(hidden_layer_size, return_sequences=True, return_state=True, dropout = dp)\n",
    "            decoder_layers.append(decoder_lstm)\n",
    "            decoder_outputs, _ , _  = decoder_lstm(decoder_outputs, initial_state=encoder_states[2])\n",
    "       \n",
    "    decoder_attention = AdditiveAttention(name=\"decoder_attention\")\n",
    "    decoder_concat    = Concatenate(name=\"decoder_concat\")\n",
    "    context_vec, attn_weights = decoder_attention([decoder_outputs, encoder_outputs], return_attention_scores=True)\n",
    "    decoder_outputs = decoder_concat([decoder_outputs, context_vec])\n",
    "  \n",
    "    decoder_dense = TimeDistributed(Dense(num_decoder_tokens, activation=\"softmax\"))\n",
    "    decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "    # MODEL\n",
    "    model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "    return model, encoder_layers, decoder_layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hwCPBckEupTX"
   },
   "source": [
    "# **Inference model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T05:23:01.686704Z",
     "iopub.status.busy": "2025-05-20T05:23:01.686197Z",
     "iopub.status.idle": "2025-05-20T05:23:01.696785Z",
     "shell.execute_reply": "2025-05-20T05:23:01.696033Z",
     "shell.execute_reply.started": "2025-05-20T05:23:01.686679Z"
    },
    "id": "cvLRxv-cCoLa",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def inferencing(model,num_encoder_layers,num_decoder_layers,encoder_layers,decoder_layers,cell_type, hidden_layer_size):\n",
    "    \n",
    "    # ENCODER MODEL RECONSTRUCTION \n",
    "    encoder_inputs = model.input[0]  # input_1\n",
    "    encoder_states = []\n",
    "    enc_emb = model.layers[2]     # embedding 1\n",
    "    encoder_outputs = enc_emb(encoder_inputs)\n",
    "\n",
    "    if cell_type == 'RNN' or cell_type ==\"GRU\":\n",
    "        for i in range(num_encoder_layers):\n",
    "            encoder_outputs, state_h_enc = encoder_layers[i](encoder_outputs)\n",
    "            encoder_states += [state_h_enc] \n",
    "    else:\n",
    "        for i in range(num_encoder_layers):\n",
    "            encoder_outputs, state_h_enc, state_c_enc = encoder_layers[i](encoder_outputs)\n",
    "            encoder_states += [state_h_enc, state_c_enc]   \n",
    "\n",
    "    encoder_model = Model(encoder_inputs, encoder_states + [encoder_outputs])\n",
    "\n",
    "\n",
    "    # DECODER MODEL RECONSTRUCTION\n",
    "    input_names = [[\"input_100\",\"input_101\"],[\"input_102\",\"input_103\"],[\"input_104\",\"input_105\"],\"input_106\"]\n",
    "\n",
    "    decoder_inputs = model.input[1]       # input_2\n",
    "    decoder_embedding = model.layers[3]   # embedding 2\n",
    "    decoder_outputs = decoder_embedding(decoder_inputs)\n",
    "    decoder_states = []\n",
    "    decoder_states_inputs = []\n",
    "    \n",
    "    if cell_type == 'RNN' or cell_type ==\"GRU\":\n",
    "        for i in range(num_decoder_layers):\n",
    "            decoder_states_inputs += [Input(shape=(hidden_layer_size,), name=input_names[i][0])]\n",
    "        for i in range(num_decoder_layers):\n",
    "            decoder_outputs, state_h_dec = decoder_layers[i](decoder_outputs, initial_state=decoder_states_inputs[i])\n",
    "            decoder_states += [state_h_dec]\n",
    "    else:\n",
    "        for i in range(num_decoder_layers):\n",
    "            decoder_states_inputs += [Input(shape=(hidden_layer_size,), name=input_names[i][0]), Input(shape=(hidden_layer_size,), name=input_names[i][1])]\n",
    "        j = 0\n",
    "        for i in range(num_decoder_layers):\n",
    "            decoder_outputs, state_h_dec, state_c_dec = decoder_layers[i](decoder_outputs, initial_state=decoder_states_inputs[i+j:i+j+2])\n",
    "            decoder_states += [state_h_dec , state_c_dec]\n",
    "            j += 1\n",
    "\n",
    "    att_layer = model.layers[4+2*num_encoder_layers]\n",
    "    attn_input = Input(shape=(max_encoder_seq_length,hidden_layer_size), name=input_names[-1])   \n",
    "\n",
    "    # context_vec, attn_weights = att_layer([decoder_outputs, attn_input], return_attention_scores=True)\n",
    "    # context_vec, attn_weights = att_layer((decoder_outputs, attn_input), return_attention_scores=True)\n",
    "    att_output = att_layer([decoder_outputs, attn_input], return_attention_scores=True)\n",
    "    context_vec = att_output[0]\n",
    "    attn_weights = att_output[1]\n",
    "\n",
    "    \n",
    "    concat_layer = model.layers[5+2*num_encoder_layers]\n",
    "    decoder_outputs = concat_layer([decoder_outputs, context_vec])\n",
    "\n",
    "    decoder_dense = model.layers[6+2*num_encoder_layers]\n",
    "    decoder_outputs = decoder_dense(decoder_outputs)\n",
    "    decoder_model = Model([decoder_inputs] + decoder_states_inputs + [attn_input], [decoder_outputs] + decoder_states + [attn_weights])\n",
    "\n",
    "    return encoder_model, decoder_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T05:23:05.300302Z",
     "iopub.status.busy": "2025-05-20T05:23:05.299684Z",
     "iopub.status.idle": "2025-05-20T05:23:05.305879Z",
     "shell.execute_reply": "2025-05-20T05:23:05.305163Z",
     "shell.execute_reply.started": "2025-05-20T05:23:05.300279Z"
    },
    "id": "iKU9UeA7q75x",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq,encoder_model,decoder_model):\n",
    "    # Encode the input as state vectors.\n",
    "    states_value = encoder_model.predict(input_seq,verbose=0)\n",
    "    attn_input = states_value[-1]\n",
    "    states_value = states_value[:-1]\n",
    "    target_seq = np.zeros((1, 1)) \n",
    "    target_seq[0, 0] = target_token_index[\"\\t\"]\n",
    "    attn_weights = []\n",
    "    stop_condition = False\n",
    "    decoded_sentence = \"\"\n",
    "    while not stop_condition:\n",
    "        output_tokens = decoder_model.predict([target_seq] + states_value + [attn_input])\n",
    "        sampled_token_index = np.argmax(output_tokens[0][0, -1, :])\n",
    "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
    "        decoded_sentence += sampled_char\n",
    "        if sampled_char == \"\\n\" or len(decoded_sentence) > max_decoder_seq_length:\n",
    "            stop_condition = True\n",
    "\n",
    "        target_seq = np.zeros((1, 1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "        states_value = output_tokens[1:-1]\n",
    "        attn_weights.append(output_tokens[-1][0][0])\n",
    "        \n",
    "    return decoded_sentence, attn_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9rf15d9ABWI0"
   },
   "source": [
    "# **Fitting the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f3tft1XVCoLY",
    "outputId": "fb414abe-fb07-49ad-ccc2-4ff6e033c3e7"
   },
   "outputs": [],
   "source": [
    "batch_size = 128        \n",
    "epochs = 7             \n",
    "input_embedding_size = 512\n",
    "hidden_layer_size = 512\n",
    "num_layers = 1\n",
    "num_encoder_layers = num_layers\n",
    "num_decoder_layers = num_layers\n",
    "dropout = 0.2\n",
    "cell_type = 'GRU'\n",
    "\n",
    "# TRAIN\n",
    "model, encoder_layers, decoder_layers = training(input_embedding_size, dropout, cell_type, hidden_layer_size, num_encoder_layers, num_decoder_layers)\n",
    "\n",
    "# COMPILE\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# FIT\n",
    "model.fit(\n",
    "    [encoder_input_data, decoder_input_data],\n",
    "    decoder_target_data,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    shuffle = True,\n",
    "    validation_data= ([encoder_val_input_data, decoder_val_input_data], decoder_val_target_data)\n",
    ")\n",
    "\n",
    "# encoder_model, decoder_model = inferencing(model, num_encoder_layers, num_decoder_layers, encoder_layers, decoder_layers, cell_type, hidden_layer_size)\n",
    "# correct = 0\n",
    "# n = val_devnagri.shape[0]\n",
    "# for i in range(n):\n",
    "#     input = encoder_val_input_data[i:i+1]\n",
    "#     output, attn_weights = decode_sequence(input,encoder_model, decoder_model)\n",
    "#     if output.strip() == val_devnagri[i].strip():\n",
    "#         correct += 1\n",
    "# print(\"Validation accuracy : \", correct*100/n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T9mXbfsmyk5Z"
   },
   "source": [
    "# **Hyperparameter Tuning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T05:23:10.285175Z",
     "iopub.status.busy": "2025-05-20T05:23:10.284604Z",
     "iopub.status.idle": "2025-05-20T05:23:10.289473Z",
     "shell.execute_reply": "2025-05-20T05:23:10.288735Z",
     "shell.execute_reply.started": "2025-05-20T05:23:10.285150Z"
    },
    "id": "IRazj-4M8VYI",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "sweep_config = {\n",
    "    'method': 'bayes',\n",
    "    'metric': {'goal': 'maximize', 'name': 'val_accuracy'},\n",
    "    'parameters': {'input_embedding_size': {'values': [128, 256, 512]},\n",
    "                   'hidden_layer_size': {'values': [128, 256, 512]},\n",
    "                   'cell_type': {'values': ['LSTM', 'RNN']},\n",
    "                   'num_layers': {'values': [1,2,3]},\n",
    "                   'batch_size': {'values': [128,256,512]},\n",
    "                   'dropout': {'values': [0.1, 0.2, 0.3, 0.4]}\n",
    "                }}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T05:23:13.719284Z",
     "iopub.status.busy": "2025-05-20T05:23:13.718731Z",
     "iopub.status.idle": "2025-05-20T05:23:13.725221Z",
     "shell.execute_reply": "2025-05-20T05:23:13.724569Z",
     "shell.execute_reply.started": "2025-05-20T05:23:13.719260Z"
    },
    "id": "l2t_HvCk0vBM",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def train():\n",
    "    var1 = wandb.init(group=\"attention\")\n",
    "    var2 = var1.config\n",
    "    epochs = 7\n",
    "\n",
    "    model, encoder_layers, decoder_layers = training(var2.input_embedding_size, var2.dropout, var2.cell_type , var2.hidden_layer_size, var2.num_layers, var2.num_layers)\n",
    "    model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "    model.fit(\n",
    "        [encoder_input_data, decoder_input_data],\n",
    "        decoder_target_data,\n",
    "        batch_size=var2.batch_size,\n",
    "        epochs=epochs,\n",
    "        # callbacks=[WandbCallback()]\n",
    "    )\n",
    "\n",
    "    encoder_model, decoder_model = inferencing(model,var2.num_layers, var2.num_layers,encoder_layers,decoder_layers,var2.cell_type,var2.hidden_layer_size)\n",
    "    correct = 0\n",
    "    n = val_devnagri.shape[0]\n",
    "    for i in range(n):\n",
    "        input = encoder_val_input_data[i:i+1]\n",
    "        output, attn_weights = decode_sequence(input,encoder_model, decoder_model)\n",
    "        if output.strip() == val_devnagri[i].strip():\n",
    "            correct += 1\n",
    "    wandb.log({'val_accuracy' : correct*100/n})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lMR1I7lL049l",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "sweep_id = wandb.sweep(sweep_config, project=\"Assignment_3\")\n",
    "wandb.agent(sweep_id, train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cAEJeXHt3Gze"
   },
   "source": [
    "# **Predictions on test set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QehJccbi4Atl",
    "outputId": "6bf45fda-4f16-4363-958e-601e2fcf0c78"
   },
   "outputs": [],
   "source": [
    "encoder_model, decoder_model = inferencing(model, num_encoder_layers, num_decoder_layers, encoder_layers, decoder_layers, cell_type, hidden_layer_size)\n",
    "correct = 0\n",
    "predictions = []\n",
    "attentions = []\n",
    "n = test_devnagri.shape[0]\n",
    "print(\"len test \", n)\n",
    "for i in range(n):\n",
    "    input = encoder_test_input_data[i:i+1]\n",
    "    output, attn_weights = decode_sequence(input,encoder_model, decoder_model)\n",
    "    attentions.append(attn_weights)\n",
    "    if output.strip() == test_devnagri[i].strip():\n",
    "        correct += 1\n",
    "    predictions.append(output.strip())\n",
    "print(\"Test accuracy : \", correct*100/n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vrAYHcLE6J0o"
   },
   "outputs": [],
   "source": [
    "# Storing predictions\n",
    "file = open('predictions_attention.csv', 'w', newline ='', encoding = 'utf-8', errors='ignore')\n",
    "  \n",
    "with file:     \n",
    "    header = ['Input', 'Prediction', 'Ground Truth']\n",
    "    writer = csv.DictWriter(file, fieldnames = header)\n",
    "    writer.writeheader()\n",
    "    for i in range(n):\n",
    "        writer.writerow({'Input' : test_english[i], 'Prediction': predictions[i], 'Ground Truth': test_devnagri[i]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hvTIB0J1Kpud"
   },
   "source": [
    "# **Attention heatmaps**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UIqlheY5KpZm"
   },
   "outputs": [],
   "source": [
    "mangal_dir=r\"/kaggle/input/mangal/MANGAL.TTF\"\n",
    "\n",
    "fig = []\n",
    "n = 9 \n",
    "fig , axs = plt.subplots(3,3)\n",
    "fig.set_size_inches(23, 15)\n",
    "l = -1\n",
    "k = 0\n",
    "for i in range(n):\n",
    "    output = predictions[i]\n",
    "    attn_weights = attentions[i]\n",
    "    ylabel = [\"\"]\n",
    "    m = len(attn_weights)\n",
    "    chars_ = [x for x in output]\n",
    "    xlabel = [\"\"]\n",
    "    ylabel += chars_\n",
    "    xlabel += [char for char in test_english[i]]\n",
    "    \n",
    "    for j in range(m):\n",
    "        attn_weights[j] = attn_weights[j][1:len(xlabel)]\n",
    "        \n",
    "    attn_weights = attn_weights[:-1]\n",
    "    if i%3 == 0:\n",
    "        l+=1\n",
    "        k=0\n",
    "    cax = axs[l][k].matshow(np.array(attn_weights))\n",
    "    axs[l][k].set_xticklabels(xlabel)\n",
    "    # xyz = FontProperties(fname = \"MANGAL.TTF\", size = 15)\n",
    "    xyz = FontProperties(fname = mangal_dir, size = 15)\n",
    "    axs[l][k].set_yticklabels(ylabel, fontproperties = xyz)\n",
    "    k+=1\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "ques5.ipynb",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 7465286,
     "sourceId": 11878680,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7465322,
     "sourceId": 11878724,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
